# âš™ï¸ è‡ªå‹•å›æ»¾å’Œè‡ªå‹•æ“´å±•é…ç½®

## ğŸš¨ è‡ªå‹•å›æ»¾ (Automatic Rollback)

### 1. åŸºæ–¼æŒ‡æ¨™çš„å›æ»¾

```yaml
# k8s/rollback-policy.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: rollback-policy
  namespace: production
data:
  policy.json: |
    {
      "rollback_triggers": [
        {
          "metric": "error_rate",
          "threshold": 0.05,
          "duration": "3m",
          "severity": "CRITICAL"
        },
        {
          "metric": "latency_p99",
          "threshold": 5000,
          "duration": "5m",
          "severity": "WARNING"
        },
        {
          "metric": "pod_ready_ratio",
          "threshold": 0.5,
          "duration": "2m",
          "severity": "CRITICAL"
        },
        {
          "metric": "memory_usage",
          "threshold": 0.9,
          "duration": "10m",
          "severity": "WARNING"
        },
        {
          "metric": "restart_count",
          "threshold": 3,
          "duration": "5m",
          "severity": "CRITICAL"
        }
      ],
      "rollback_strategy": {
        "automatic": true,
        "max_rollback_attempts": 3,
        "wait_between_attempts_seconds": 30
      }
    }
```

### 2. è‡ªå‹•å›æ»¾æ§åˆ¶å™¨

```bash
#!/bin/bash
# scripts/auto-rollback-controller.sh

set -e

NAMESPACE="production"
PROMETHEUS_URL="http://prometheus:9090"
CHECK_INTERVAL=30
ALERT_WEBHOOK="${SLACK_WEBHOOK_URL}"

# å›æ»¾é…ç½®
declare -A ROLLBACK_THRESHOLDS=(
    ["error_rate"]=0.05
    ["latency_p99"]=5000
    ["pod_ready"]=0.5
)

declare -A ROLLBACK_DURATION=(
    ["error_rate"]="3m"
    ["latency_p99"]="5m"
    ["pod_ready"]="2m"
)

log_alert() {
    local message=$1
    echo "[$(date)] ğŸš¨ ALERT: $message"
    
    # ç™¼é€åˆ° Slack
    curl -X POST "$ALERT_WEBHOOK" \
        -H 'Content-type: application/json' \
        --data "{
            \"text\": \"ğŸš¨ Auto-Rollback Triggered\",
            \"attachments\": [{
                \"color\": \"danger\",
                \"text\": \"$message\"
            }]
        }"
}

query_prometheus() {
    local query=$1
    curl -s "${PROMETHEUS_URL}/api/v1/query" \
        --data-urlencode "query=$query" | \
        jq -r '.data.result[0].value[1]' 2>/dev/null || echo "0"
}

check_error_rate() {
    local query='rate(http_requests_total{namespace="'$NAMESPACE'",status=~"5.."}[3m])'
    local error_rate=$(query_prometheus "$query")
    local threshold=${ROLLBACK_THRESHOLDS["error_rate"]}
    
    if (( $(echo "$error_rate > $threshold" | bc -l) )); then
        return 0  # è§¸ç™¼å›æ»¾
    fi
    return 1
}

check_latency() {
    local query='histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{namespace="'$NAMESPACE'"}[5m]))'
    local latency=$(query_prometheus "$query")
    local threshold=${ROLLBACK_THRESHOLDS["latency_p99"]}
    
    if (( $(echo "$latency > $threshold" | bc -l) )); then
        return 0  # è§¸ç™¼å›æ»¾
    fi
    return 1
}

check_pod_health() {
    local ready_pods=$(kubectl get pods -n "$NAMESPACE" \
        -l app=recommendation-service \
        -o jsonpath='{.items[?(@.status.conditions[?(@.type=="Ready")].status=="True")].metadata.name}' | \
        wc -w)
    
    local total_pods=$(kubectl get pods -n "$NAMESPACE" \
        -l app=recommendation-service \
        -o jsonpath='{.items[*].metadata.name}' | \
        wc -w)
    
    if [ "$total_pods" -gt 0 ]; then
        local ready_ratio=$(echo "scale=2; $ready_pods / $total_pods" | bc)
        local threshold=${ROLLBACK_THRESHOLDS["pod_ready"]}
        
        if (( $(echo "$ready_ratio < $threshold" | bc -l) )); then
            return 0  # è§¸ç™¼å›æ»¾
        fi
    fi
    return 1
}

perform_rollback() {
    local deployment=$1
    local namespace=$2
    
    log_alert "Initiating automatic rollback for $deployment in $namespace"
    
    # åŸ·è¡Œå›æ»¾
    kubectl rollout undo deployment/"$deployment" -n "$namespace"
    
    # ç­‰å¾…å›æ»¾å®Œæˆ
    kubectl rollout status deployment/"$deployment" -n "$namespace" --timeout=10m
    
    log_alert "Rollback completed for $deployment"
}

main() {
    echo "Starting Auto-Rollback Controller"
    
    while true; do
        # æª¢æŸ¥å„é …æŒ‡æ¨™
        if check_error_rate; then
            log_alert "Error rate exceeded threshold"
            perform_rollback "recommendation-service" "$NAMESPACE"
        elif check_latency; then
            log_alert "Latency exceeded threshold"
            perform_rollback "recommendation-service" "$NAMESPACE"
        elif check_pod_health; then
            log_alert "Pod health check failed"
            perform_rollback "recommendation-service" "$NAMESPACE"
        fi
        
        sleep $CHECK_INTERVAL
    done
}

trap 'echo "Auto-Rollback Controller stopped"; exit 0' SIGTERM SIGINT
main
```

### 3. Kubernetes Deployment é…ç½®

```yaml
# k8s/deployment-with-rollback.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: recommendation-service
  namespace: production
  labels:
    app: recommendation-service
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  revisionHistoryLimit: 10  # ä¿ç•™æœ€å¾Œ 10 å€‹ç‰ˆæœ¬ç”¨æ–¼å›æ»¾
  
  progressDeadlineSeconds: 600  # 10 åˆ†é˜å…§æœªå®Œæˆå‰‡å¤±æ•—
  
  selector:
    matchLabels:
      app: recommendation-service
  
  template:
    metadata:
      labels:
        app: recommendation-service
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3000"
        prometheus.io/path: "/metrics"
    
    spec:
      containers:
      - name: app
        image: registry.example.com/recommendation-service:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 3000
          name: http
        - containerPort: 9090
          name: metrics
        
        # å°±ç·’æ¢é‡ (Readiness Probe)
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        
        # æ´»èºæ¢é‡ (Liveness Probe)
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 20
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
        
        # å•Ÿå‹•æ¢é‡ (Startup Probe) - K8s 1.16+
        startupProbe:
          httpGet:
            path: /health
            port: 3000
          failureThreshold: 30
          periodSeconds: 5
        
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        
        env:
        - name: NODE_ENV
          value: "production"
        - name: LOG_LEVEL
          value: "info"
```

---

## ğŸ“ˆ è‡ªå‹•æ“´å±• (Autoscaling)

### 1. æ°´å¹³ Pod è‡ªå‹•æ“´å±• (HPA)

```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: recommendation-service-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: recommendation-service
  
  minReplicas: 3
  maxReplicas: 20
  
  metrics:
  # åŸºæ–¼ CPU ä½¿ç”¨ç‡
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  
  # åŸºæ–¼å…§å­˜ä½¿ç”¨ç‡
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  
  # åŸºæ–¼è‡ªå®šç¾©æŒ‡æ¨™ (è«‹æ±‚æ•¸)
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "1000"
  
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Min
    
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 4
        periodSeconds: 30
      selectPolicy: Max

---
# å…¶ä»–æœå‹™çš„ HPA
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: content-service-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: content-streaming-service
  minReplicas: 2
  maxReplicas: 15
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
```

### 2. ç¯€é»è‡ªå‹•æ“´å±• (Cluster Autoscaler)

```yaml
# k8s/cluster-autoscaler-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-config
  namespace: kube-system
data:
  config.yaml: |
    nodeGroups:
    - name: compute-pool-1
      minSize: 3
      maxSize: 10
      desiredSize: 5
      machineType: t3.large
      autoRepair: true
      autoUpgrade: true
    
    - name: compute-pool-2
      minSize: 2
      maxSize: 8
      desiredSize: 3
      machineType: t3.xlarge
      autoRepair: true
      autoUpgrade: true
    
    scaling:
      scaleDownEnabled: true
      scaleDownDelay: 10m
      scaleDownUnneededTime: 10m
      skipNodesWithLocalStorage: true
```

### 3. å‚ç›´ Pod è‡ªå‹•èª¿æ•´ (VPA - å¯é¸)

```yaml
# k8s/vpa.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: recommendation-service-vpa
  namespace: production
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: recommendation-service
  
  updatePolicy:
    updateMode: "Auto"  # è‡ªå‹•æ›´æ–°è³‡æºè«‹æ±‚
  
  resourcePolicy:
    containerPolicies:
    - containerName: "app"
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 2Gi
```

---

## ğŸ“Š ç›£æ§å’Œå‘Šè­¦

### CloudWatch / Prometheus å‘Šè­¦è¦å‰‡

```yaml
# monitoring/alert-rules.yaml
groups:
- name: auto-scaling.rules
  interval: 30s
  rules:
  
  # æ“´å±•äº‹ä»¶
  - alert: PodScalingUp
    expr: |
      increase(hpa_desired_replicas{namespace="production"}[1m]) > 0
    for: 1m
    annotations:
      summary: "HPA æ­£åœ¨æ“´å±•"
      description: "{{ $labels.hpa }} åœ¨æ“´å±•ä¸­"
  
  # é”åˆ°æœ€å¤§å‰¯æœ¬æ•¸
  - alert: HPAAtMaxReplicas
    expr: |
      hpa_desired_replicas{namespace="production"} >= hpa_max_replicas
    for: 5m
    annotations:
      summary: "HPA å·²é”åˆ°æœ€å¤§å‰¯æœ¬æ•¸"
      description: "{{ $labels.hpa }} ç„¡æ³•ç¹¼çºŒæ“´å±•"
  
  # é »ç¹æ“´ç¸®
  - alert: FrequentScaling
    expr: |
      rate(hpa_scaling_activity_total[5m]) > 0.1
    for: 10m
    annotations:
      summary: "æª¢æ¸¬åˆ°é »ç¹çš„è‡ªå‹•æ“´å±•"
      description: "{{ $labels.hpa }} æ“´å±•é »ç‡éé«˜ï¼Œå¯èƒ½éœ€è¦èª¿æ•´é–¾å€¼"
  
  # å›æ»¾äº‹ä»¶
  - alert: RollbackDetected
    expr: |
      increase(deployment_rollback_total{namespace="production"}[1m]) > 0
    for: 1m
    annotations:
      summary: "æª¢æ¸¬åˆ°éƒ¨ç½²å›æ»¾"
      description: "{{ $labels.deployment }} å·²è§¸ç™¼è‡ªå‹•å›æ»¾"
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### æª¢æŸ¥ HPA ç‹€æ…‹

```bash
# æŸ¥çœ‹ HPA é…ç½®
kubectl get hpa -n production
kubectl describe hpa recommendation-service-hpa -n production

# æª¢æŸ¥ HPA äº‹ä»¶
kubectl get events -n production | grep -i hpa

# æŸ¥çœ‹æŒ‡æ¨™å€¼
kubectl get hpa recommendation-service-hpa -n production -w

# æª¢æŸ¥ç•¶å‰å‰¯æœ¬æ•¸
kubectl get deployment recommendation-service -n production
```

### å¸¸è¦‹å•é¡Œ

| å•é¡Œ | ç—‡ç‹€ | è§£æ±ºæ–¹æ¡ˆ |
|------|------|---------|
| HPA ç„¡æ³•å·¥ä½œ | å‰¯æœ¬æ•¸ä¸è®Š | æª¢æŸ¥ Metrics Server æ˜¯å¦é‹è¡Œ |
| ç„¡æ³•ç²å–æŒ‡æ¨™ | "unable to compute replica count" | ç¢ºèª Pod å°å‡ºäº†æ­£ç¢ºçš„æŒ‡æ¨™ |
| é »ç¹æ“´ç¸® | Pod ä¸æ–·é‡å•Ÿ | èª¿æ•´ stabilizationWindowSeconds |
| ç„¡æ³•æ“´å±•åˆ°æœ€å¤§ | ç„¡æ³•æ“´å±•åˆ° maxReplicas | æª¢æŸ¥è³‡æºé…é¡é™åˆ¶ |

---

## ğŸ“‹ æª¢æŸ¥æ¸…å–®

### éƒ¨ç½²å‰é…ç½®

- [ ] HPA é…ç½®å·²é©—è­‰
- [ ] è³‡æºè«‹æ±‚å’Œé™åˆ¶å·²è¨­ç½®
- [ ] å¥åº·æª¢æŸ¥å·²é…ç½®
- [ ] å‘Šè­¦è¦å‰‡å·²é…ç½®
- [ ] æ—¥èªŒå·²é…ç½®

### éƒ¨ç½²å¾Œé©—è­‰

- [ ] HPA æ­£å¸¸å·¥ä½œ
- [ ] è‡ªå‹•æ“´å±•åœ¨é«˜è² è¼‰ä¸‹è§¸ç™¼
- [ ] è‡ªå‹•ç¸®å®¹å·¥ä½œæ­£å¸¸
- [ ] å‘Šè­¦é€šçŸ¥æ­£å¸¸é‹è¡Œ
- [ ] ç„¡é »ç¹çš„æ“´ç¸®äº‹ä»¶

---

**å»ºè­°**: å®šæœŸæª¢æŸ¥å’Œèª¿æ•´ HPA é–¾å€¼ï¼Œç¢ºä¿è³‡æºä½¿ç”¨æ•ˆç‡å’Œæ‡‰ç”¨ç©©å®šæ€§ã€‚
