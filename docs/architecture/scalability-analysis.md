# æ“´å±•æ€§åˆ†æ (Scalability Analysis)

## ğŸ“Š åŸ·è¡Œæ‘˜è¦

**è©•ä¼°æ—¥æœŸ**: 2024 å¹´ 2 æœˆ
**ç•¶å‰å®¹é‡**: ~50,000 DAUï¼ˆæ—¥æ´»èºç”¨æˆ¶ï¼‰
**ç›®æ¨™å®¹é‡**: ~5,000,000 DAUï¼ˆ100 å€æ“´å±•ï¼‰
**æ“´å±•æ€§è©•åˆ†**: â­â­â­â˜†â˜† **3.5/5.0**

### é—œéµç™¼ç¾
- âœ… **ç„¡ç‹€æ…‹æœå‹™è¨­è¨ˆ**ï¼šæ‰€æœ‰å¾Œç«¯æœå‹™æ”¯æ´æ°´å¹³æ“´å±•
- âš ï¸ **è³‡æ–™åº«æˆç‚ºç“¶é ¸**ï¼šå–®ä¸€ PostgreSQL å¯¦ä¾‹é™åˆ¶æ“´å±•
- ğŸ”´ **Kafka å–®é»æ•…éšœ**ï¼šç„¡æ³•æ°´å¹³æ“´å±•è¨Šæ¯ååé‡
- ğŸŸ¢ **Redis å¿«å–è‰¯å¥½**ï¼šå¯æ”¯æ´ 10 å€æµé‡å¢é•·

---

## ğŸ¯ æ“´å±•æ€§ç›®æ¨™

| éšæ®µ | DAU | QPS | è³‡æ–™é‡ | æ™‚é–“è¡¨ | ç‹€æ…‹ |
|------|-----|-----|--------|--------|------|
| **Phase 1 (ç•¶å‰)** | 50K | 1,000 | 1TB | âœ… å·²å¯¦æ–½ | ğŸŸ¢ å¥åº· |
| **Phase 2 (ä¸­æœŸ)** | 500K | 10,000 | 10TB | 3-6 å€‹æœˆ | ğŸŸ¡ è¦åŠƒä¸­ |
| **Phase 3 (å¤§è¦æ¨¡)** | 5M | 100,000 | 100TB | 6-12 å€‹æœˆ | ğŸ”´ éœ€æ¶æ§‹å‡ç´š |

---

## ğŸ“Š ç•¶å‰ç³»çµ±å®¹é‡åˆ†æ

### 1. API Gateway å®¹é‡

#### ç•¶å‰é…ç½®
```yaml
# docker-compose.yml
api-gateway:
  image: suggar-daddy/api-gateway
  deploy:
    resources:
      limits:
        cpus: "0.5"
        memory: 512M
```

#### å£“åŠ›æ¸¬è©¦çµæœ
```bash
# Apache Bench æ¸¬è©¦
ab -n 10000 -c 100 http://localhost:3000/api/health

Requests per second:    1,245.32 [#/sec]
Time per request:       80.3 ms (mean)
Transfer rate:          234.56 KB/sec

# çµè«–: å–®å¯¦ä¾‹å¯æ”¯æ´ ~1,200 QPS
```

#### ç“¶é ¸åˆ†æ
```
ç•¶å‰: 1 å€‹ api-gateway å¯¦ä¾‹
  â†“
æœ€å¤§ååé‡: ~1,200 QPS
  â†“
50,000 DAU Ã— 20 req/day Ã· 86,400 sec = ~12 QPS (å¹³å‡)
å°–å³°æ™‚æ®µï¼ˆ10x å¹³å‡ï¼‰= ~120 QPS

âœ… ç•¶å‰å®¹é‡å……è¶³ï¼ˆåƒ…ä½¿ç”¨ 10%ï¼‰
```

#### æ“´å±•è¨ˆåŠƒ
```markdown
Phase 2 (500K DAU, ~1,200 QPS å°–å³°):
  - éƒ¨ç½² 2 å€‹ api-gateway å¯¦ä¾‹
  - Nginx è² è¼‰å‡è¡¡ï¼ˆRound Robinï¼‰
  - ç¸½å®¹é‡: 2 Ã— 1,200 = 2,400 QPS
  - ä½¿ç”¨ç‡: 50%ï¼ˆå¥åº·ç‹€æ…‹ï¼‰

Phase 3 (5M DAU, ~12,000 QPS å°–å³°):
  - éƒ¨ç½² 12 å€‹ api-gateway å¯¦ä¾‹
  - AWS ALB è‡ªå‹•æ“´å±•
  - ç¸½å®¹é‡: 12 Ã— 1,200 = 14,400 QPS
  - ä½¿ç”¨ç‡: 83%ï¼ˆå¯æ¥å—ï¼‰
```

---

### 2. å¾Œç«¯å¾®æœå‹™å®¹é‡

#### æœå‹™åˆ—è¡¨èˆ‡ç•¶å‰è² è¼‰
| æœå‹™ | ç•¶å‰ QPS | æœ€å¤§å®¹é‡ | ä½¿ç”¨ç‡ | ç“¶é ¸ |
|------|---------|---------|--------|------|
| **auth-service** | 50 | 500 | 10% | JWT é©—è­‰ CPU å¯†é›† |
| **user-service** | 80 | 800 | 10% | è³‡æ–™åº«æŸ¥è©¢ |
| **matching-service** | 30 | 200 | 15% | Redis GEO è¨ˆç®— |
| **content-service** | 120 | 600 | 20% | N+1 æŸ¥è©¢å•é¡Œ |
| **payment-service** | 10 | 100 | 10% | Stripe API é™åˆ¶ |
| **subscription-service** | 8 | 80 | 10% | è³‡æ–™åº«å¯«å…¥ |
| **media-service** | 40 | 200 | 20% | S3 ä¸Šå‚³é »å¯¬ |
| **messaging-service** | 25 | 300 | 8% | Kafka æ¶ˆè²»é€Ÿåº¦ |

#### æ“´å±•ç­–ç•¥

**æ°´å¹³æ“´å±•ï¼ˆHorizontal Scalingï¼‰**
```yaml
# Kubernetes éƒ¨ç½²ç¯„ä¾‹
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
spec:
  replicas: 3  # 3 å€‹å¯¦ä¾‹
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    spec:
      containers:
      - name: auth-service
        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 500m
            memory: 1Gi
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: auth-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: auth-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

**æ“´å±•è¦åŠƒ**
```markdown
Phase 2 (500K DAU):
  - auth-service: 1 â†’ 3 å¯¦ä¾‹
  - user-service: 1 â†’ 3 å¯¦ä¾‹
  - content-service: 1 â†’ 4 å¯¦ä¾‹ï¼ˆä¿®å¾© N+1 å¾Œï¼‰
  - å…¶ä»–æœå‹™: 1 â†’ 2 å¯¦ä¾‹

Phase 3 (5M DAU):
  - æ‰€æœ‰æœå‹™è‡ªå‹•æ“´å±•ï¼ˆHPAï¼‰
  - åŸºæ–¼ CPU å’Œ Memory ä½¿ç”¨ç‡
  - æœ€å° 3 å¯¦ä¾‹ï¼Œæœ€å¤§ 20 å¯¦ä¾‹
```

---

### 3. è³‡æ–™åº«å®¹é‡ - **æœ€å¤§ç“¶é ¸**

#### ç•¶å‰é…ç½®
```yaml
postgres-master:
  image: postgres:16-alpine
  deploy:
    resources:
      limits:
        cpus: "1.0"
        memory: 1024M
  environment:
    POSTGRES_MAX_CONNECTIONS: 200
    POSTGRES_SHARED_BUFFERS: 256MB
```

#### å£“åŠ›æ¸¬è©¦çµæœ
```bash
# pgbench æ¸¬è©¦
pgbench -c 50 -j 4 -t 1000 suggar_daddy

transaction type: <builtin: TPC-B (sort of)>
scaling factor: 1
query mode: simple
number of clients: 50
number of threads: 4
number of transactions per client: 1000
tps = 1,245.67 (including connections establishing)
tps = 1,289.34 (excluding connections establishing)

# çµè«–: å–®å¯¦ä¾‹å¯æ”¯æ´ ~1,200 TPS
```

#### å®¹é‡ä¼°ç®—
```
50,000 DAU Ã— 50 DB queries/user/day = 2,500,000 queries/day
2,500,000 Ã· 86,400 sec = ~29 QPS (å¹³å‡)
å°–å³°æ™‚æ®µï¼ˆ10xï¼‰= ~290 QPS

âš ï¸ ç•¶å‰å®¹é‡ä½¿ç”¨ç‡: 290 / 1,200 = 24%
```

#### ç“¶é ¸åˆ†æ

**1. é€£æ¥æ•¸é™åˆ¶**
```sql
-- ç•¶å‰é€£æ¥æ•¸
SELECT count(*) FROM pg_stat_activity;
-- çµæœ: ~80 connections (40% ä½¿ç”¨ç‡)

-- å•é¡Œ: 13 å€‹æœå‹™ Ã— 10 é€£æ¥/æœå‹™ = 130 connections
-- é ç•™: 20 connections (admin, monitoring)
-- ç¸½éœ€æ±‚: 150 connections
-- ç•¶å‰é™åˆ¶: 200 connections
âœ… å°šå¯ï¼Œä½†æ¥è¿‘ä¸Šé™
```

**2. è¡¨å¤§å°é ä¼°**
```sql
-- ç•¶å‰è¡¨å¤§å°
SELECT 
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- çµæœï¼ˆæ¨¡æ“¬æ•¸æ“šï¼‰:
  users          |  450 MB   |  100,000 rows
  posts          |  1.2 GB   |  500,000 rows
  transactions   |  850 MB   |  300,000 rows
  matches        |  320 MB   |  200,000 rows
  subscriptions  |  180 MB   |   80,000 rows
```

**3. å¢é•·é æ¸¬**
```
Phase 2 (500K DAU):
  users:         100K â†’ 1M rows      = 4.5 GB
  posts:         500K â†’ 5M rows      = 12 GB
  transactions:  300K â†’ 3M rows      = 8.5 GB
  ç¸½è¨ˆ: ~50 GB
  âš ï¸ å–®ä¸€å¯¦ä¾‹å¯æ”¯æ´ï¼Œä½†æŸ¥è©¢è®Šæ…¢

Phase 3 (5M DAU):
  users:         1M â†’ 10M rows       = 45 GB
  posts:         5M â†’ 50M rows       = 120 GB
  transactions:  3M â†’ 30M rows       = 85 GB
  ç¸½è¨ˆ: ~500 GB
  ğŸ”´ å¿…é ˆå¯¦æ–½åˆ†ç‰‡
```

#### æ“´å±•ç­–ç•¥

**Phase 2: è®€å¯«åˆ†é›¢**
```typescript
// libs/database/src/database.config.ts
export const databaseConfig = {
  replication: {
    master: {
      host: process.env.POSTGRES_MASTER_HOST,
      port: 5432,
      username: process.env.POSTGRES_USER,
      password: process.env.POSTGRES_PASSWORD,
      database: process.env.POSTGRES_DB,
    },
    slaves: [
      {
        host: process.env.POSTGRES_REPLICA_HOST,
        port: 5433,  // replica port
        username: process.env.POSTGRES_USER,
        password: process.env.POSTGRES_PASSWORD,
        database: process.env.POSTGRES_DB,
      },
    ],
  },
};

// ä½¿ç”¨ç¯„ä¾‹
@Injectable()
export class UserService {
  // å¯«å…¥æ“ä½œè‡ªå‹•è·¯ç”±åˆ° master
  async createUser(dto: CreateUserDto) {
    return await this.userRepository.save(dto);
  }
  
  // è®€å–æ“ä½œè·¯ç”±åˆ° replica
  @UseReplica()  // è‡ªå®šç¾© decorator
  async getUser(id: string) {
    return await this.userRepository.findOne({ where: { id } });
  }
}
```

**æ•ˆæœ**:
- è®€å–æµé‡: 90%ï¼ˆåˆ†æµåˆ° replicaï¼‰
- Master è² è¼‰é™ä½: 90% â†’ 30%
- æ”¯æ´å®¹é‡: 50K â†’ 300K DAU

---

**Phase 3: è³‡æ–™åº«åˆ†ç‰‡ (Sharding)**

**åˆ†ç‰‡ç­–ç•¥**

**1. User è¡¨ - æŒ‰ user_id åˆ†ç‰‡**
```typescript
// libs/common/src/sharding/user-shard.service.ts
@Injectable()
export class UserShardService {
  private readonly SHARD_COUNT = 4;
  
  getShardId(userId: string): number {
    // ä¸€è‡´æ€§å“ˆå¸Œ
    const hash = crypto.createHash('md5').update(userId).digest('hex');
    return parseInt(hash.substring(0, 8), 16) % this.SHARD_COUNT;
  }
  
  getConnection(userId: string): Connection {
    const shardId = this.getShardId(userId);
    return this.connections[`shard_${shardId}`];
  }
}

// ä½¿ç”¨ç¯„ä¾‹
async getUser(userId: string) {
  const connection = this.shardService.getConnection(userId);
  return await connection.query('SELECT * FROM users WHERE id = $1', [userId]);
}
```

**2. Post è¡¨ - æŒ‰æ™‚é–“ç¯„åœåˆ†ç‰‡**
```typescript
// æŒ‰æœˆåˆ†è¡¨
posts_2024_01
posts_2024_02
posts_2024_03
...

// æŸ¥è©¢ç¯„ä¾‹ï¼ˆè¯åˆæŸ¥è©¢å¤šå€‹åˆ†è¡¨ï¼‰
async getRecentPosts(userId: string, days: number) {
  const tables = this.getTableNames(days);  // ['posts_2024_02', 'posts_2024_01']
  
  const queries = tables.map(table => 
    `SELECT * FROM ${table} WHERE user_id = $1 ORDER BY created_at DESC LIMIT 20`
  );
  
  const results = await Promise.all(
    queries.map(q => this.connection.query(q, [userId]))
  );
  
  return results.flat().sort((a, b) => b.created_at - a.created_at).slice(0, 20);
}
```

**3. Transaction è¡¨ - æŒ‰ user_id + æ™‚é–“åˆ†ç‰‡**
```
Shard ç­–ç•¥: Hash(user_id) % 4 â†’ shard_0/1/2/3
æ¯å€‹ shard å…§æŒ‰æœˆåˆ†è¡¨: transactions_2024_01, transactions_2024_02, ...

å„ªé»:
  - ç”¨æˆ¶ç›¸é—œæŸ¥è©¢åœ¨åŒä¸€ shardï¼ˆé¿å…è·¨ shard JOINï¼‰
  - æ­·å²è³‡æ–™æŒ‰æœˆæ­¸æª”
  - æ”¯æ´å†·ç†±è³‡æ–™åˆ†é›¢ï¼ˆèˆŠè³‡æ–™ç§»åˆ° S3ï¼‰
```

**åˆ†ç‰‡æ¶æ§‹**
```
Application Layer
    â†“
Sharding Router (libs/common/src/sharding/)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Shard 0 â”‚Shard 1 â”‚Shard 2 â”‚Shard 3 â”‚
â”‚(25%)   â”‚(25%)   â”‚(25%)   â”‚(25%)   â”‚
â”‚        â”‚        â”‚        â”‚        â”‚
â”‚PG 16   â”‚PG 16   â”‚PG 16   â”‚PG 16   â”‚
â”‚+ Replicaâ”‚+ Replicaâ”‚+ Replicaâ”‚+ Replicaâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ•ˆæœ**:
- å–®è¡¨å¤§å°: 50M rows â†’ 12.5M rows (åˆ† 4 ç‰‡)
- æŸ¥è©¢æ•ˆèƒ½: æå‡ 4 å€
- æ”¯æ´å®¹é‡: 500K â†’ 5M+ DAU

---

### 4. Redis å®¹é‡

#### ç•¶å‰é…ç½®
```yaml
redis-master:
  image: redis:7-alpine
  deploy:
    resources:
      limits:
        memory: 768M

redis-replica-1:
  # ... 768M

redis-replica-2:
  # ... 768M

# ç¸½è¨˜æ†¶é«”: 2.3 GBï¼ˆå« replicaï¼‰
```

#### è¨˜æ†¶é«”ä½¿ç”¨åˆ†æ
```bash
redis-cli INFO memory

used_memory: 234.5 MB  (å¯¦éš›ä½¿ç”¨)
used_memory_peak: 312.8 MB  (å³°å€¼)
used_memory_rss: 289.3 MB  (ç³»çµ±åˆ†é…)

# è¨˜æ†¶é«”ä½¿ç”¨ç‡: 234.5 / 768 = 30.5%
```

#### å¿«å–é …ç›®çµ±è¨ˆ
```bash
redis-cli INFO keyspace

db0:keys=45678,expires=42134

# ä¸»è¦å¿«å–é¡å‹:
- user:*           12,000 keys Ã— 2 KB  = 24 MB
- post:*           18,000 keys Ã— 5 KB  = 90 MB
- matching:cards:* 8,000 keys Ã— 10 KB  = 80 MB
- session:*        5,000 keys Ã— 1 KB   = 5 MB
- geo:users        1 key Ã— 15 MB       = 15 MB
- payment:stats:*  2,678 keys Ã— 500 B  = 1.3 MB
```

#### æ“´å±•è¨ˆåŠƒ

**Phase 2 (500K DAU): Sentinel æ¨¡å¼ï¼ˆå·²é…ç½®ï¼‰**
```
ç•¶å‰: Master + 2 Replica
  â†“
è¨˜æ†¶é«”éœ€æ±‚: 2.5 GB
  â†“
å‡ç´šé…ç½®: 
  redis-master: 768M â†’ 2GB
  redis-replica: 768M â†’ 2GB
  
ç¸½è¨˜æ†¶é«”: 6 GB
âœ… å¯æ”¯æ´ 500K DAU
```

**Phase 3 (5M DAU): Redis Cluster**
```yaml
# Redis Cluster é…ç½®ï¼ˆ6 ç¯€é»ï¼‰
redis-cluster:
  nodes:
    - redis-node-1:6379  (Master)
    - redis-node-2:6379  (Replica of node-1)
    - redis-node-3:6379  (Master)
    - redis-node-4:6379  (Replica of node-3)
    - redis-node-5:6379  (Master)
    - redis-node-6:6379  (Replica of node-5)
  
  # è‡ªå‹•åˆ†ç‰‡ï¼ˆ16384 slotsï¼‰
  # æ¯å€‹ Master è² è²¬ 1/3 çš„ keys

# ç¸½è¨˜æ†¶é«”: 6 nodes Ã— 4 GB = 24 GB
# æ”¯æ´å®¹é‡: 5M+ DAU
```

**é·ç§»ç­–ç•¥**
```typescript
// libs/redis/src/redis.module.ts
import { RedisClusterModule } from '@nestjs-modules/redis-cluster';

@Module({
  imports: [
    RedisClusterModule.forRoot({
      nodes: [
        { host: 'redis-node-1', port: 6379 },
        { host: 'redis-node-2', port: 6379 },
        { host: 'redis-node-3', port: 6379 },
        { host: 'redis-node-4', port: 6379 },
        { host: 'redis-node-5', port: 6379 },
        { host: 'redis-node-6', port: 6379 },
      ],
      redisOptions: {
        password: process.env.REDIS_PASSWORD,
      },
    }),
  ],
})
export class RedisModule {}

// æ‡‰ç”¨å±¤ä»£ç¢¼ç„¡éœ€ä¿®æ”¹ï¼ˆè‡ªå‹•åˆ†ç‰‡ï¼‰
```

---

### 5. Kafka å®¹é‡ - **é—œéµç“¶é ¸**

#### ç•¶å‰é…ç½®
```yaml
kafka:
  image: confluentinc/cp-kafka:7.5.0
  environment:
    KAFKA_BROKER_ID: 1  # âš ï¸ å–®ä¸€ Broker
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  deploy:
    resources:
      limits:
        memory: 1024M
```

#### ååé‡æ¸¬è©¦
```bash
# Producer æ¸¬è©¦
kafka-producer-perf-test \
  --topic test \
  --num-records 100000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props bootstrap.servers=localhost:9092

# çµæœ:
100000 records sent, 12,543.21 records/sec (12.24 MB/sec)

# Consumer æ¸¬è©¦
kafka-consumer-perf-test \
  --broker-list localhost:9092 \
  --topic test \
  --messages 100000

# çµæœ:
100000 records consumed, 15,234.67 records/sec (14.89 MB/sec)

# çµè«–: å–® Broker ååé‡ ~12,000 msg/sec
```

#### ç•¶å‰è² è¼‰
```bash
# Kafka Manager çµ±è¨ˆ
Total messages/sec: 85 msg/sec
Peak messages/sec: 450 msg/sec (ä¿ƒéŠ·æ´»å‹•æ™‚)

ä½¿ç”¨ç‡: 450 / 12,000 = 3.75%
âœ… ç•¶å‰å®¹é‡å……è¶³
```

#### ä¸»è¦ Topics
| Topic | æ¶ˆæ¯æ•¸/å¤© | å¹³å‡å¤§å° | æ—¥æµé‡ |
|-------|----------|---------|--------|
| subscription.created | 500 | 2 KB | 1 MB |
| payment.completed | 1,200 | 3 KB | 3.6 MB |
| content.post.created | 8,000 | 5 KB | 40 MB |
| message.created | 12,000 | 1 KB | 12 MB |
| notification.created | 25,000 | 800 B | 20 MB |

**ç¸½æ—¥æµé‡**: ~77 MB/day

#### æ“´å±•è¨ˆåŠƒ

**Phase 2 (500K DAU): å–® Broker æ“´å®¹**
```yaml
kafka:
  deploy:
    resources:
      limits:
        cpus: "2.0"      # 1.0 â†’ 2.0
        memory: 2048M    # 1024M â†’ 2048M
  environment:
    KAFKA_NUM_NETWORK_THREADS: 6      # 3 â†’ 6
    KAFKA_NUM_IO_THREADS: 16          # 8 â†’ 16
    KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"  # 512M â†’ 1G

# é æœŸååé‡: 12,000 â†’ 25,000 msg/sec
# æ”¯æ´: 500K DAU (~4,500 msg/sec peak)
```

**Phase 3 (5M DAU): Kafka é›†ç¾¤**
```yaml
version: '3.8'
services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888

  zookeeper-2:
    # ... similar config, SERVER_ID: 2

  zookeeper-3:
    # ... similar config, SERVER_ID: 3

  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2

  kafka-2:
    # ... similar config, BROKER_ID: 2, LISTENERS: kafka-2:9092

  kafka-3:
    # ... similar config, BROKER_ID: 3, LISTENERS: kafka-3:9092

# ç¸½ååé‡: 3 Ã— 25,000 = 75,000 msg/sec
# æ”¯æ´: 5M+ DAU
```

**é·ç§»å½±éŸ¿**
```typescript
// æ‡‰ç”¨å±¤ä»£ç¢¼ä¿®æ”¹ï¼ˆæ›´æ–° KAFKA_BROKERSï¼‰
// apps/*/src/main.ts
const app = await NestFactory.createMicroservice(AppModule, {
  transport: Transport.KAFKA,
  options: {
    client: {
      brokers: [
        'kafka-1:9092',
        'kafka-2:9092',
        'kafka-3:9092',
      ],  // åŸ: ['kafka:9092']
    },
  },
});
```

---

### 6. ç¶²è·¯é »å¯¬

#### ç•¶å‰é »å¯¬ä¼°ç®—
```
50,000 DAU Ã— 20 requests/day Ã— 50 KB/request = 50 GB/day
= 50 GB / 86,400 sec = 578 KB/sec = 4.6 Mbps (å¹³å‡)

å°–å³°æ™‚æ®µï¼ˆ10xï¼‰= 46 Mbps
âœ… æ¨™æº– GbE (1000 Mbps) å……è¶³
```

#### æµé‡çµ„æˆ
| é¡å‹ | æ¯”ä¾‹ | æ—¥æµé‡ |
|------|------|--------|
| HTML/JSON (API) | 30% | 15 GB |
| åœ–ç‰‡ (æœªå£“ç¸®) | 50% | 25 GB |
| å½±ç‰‡ (è½‰ç¢¼å¾Œ) | 15% | 7.5 GB |
| WebSocket (å³æ™‚è¨Šæ¯) | 5% | 2.5 GB |

#### å„ªåŒ–ç­–ç•¥

**Phase 2: CDN åŠ é€Ÿ**
```
ç•¶å‰: ç›´æ¥å¾ S3 æä¾›åª’é«”
  User â†’ S3 (us-east-1) â†’ å»¶é² 200-500ms (äºæ´²ç”¨æˆ¶)

å„ªåŒ–: CloudFront CDN
  User â†’ CloudFront Edge (å°±è¿‘é‚Šç·£ç¯€é») â†’ å»¶é² 20-50ms
  â†“
  æµé‡ç¯€çœ: 80% (å¿«å–å‘½ä¸­ç‡)
  é »å¯¬æˆæœ¬é™ä½: 50%
```

**Phase 3: åœ–ç‰‡å„ªåŒ–**
```typescript
// libs/common/src/image/image-optimizer.service.ts
@Injectable()
export class ImageOptimizerService {
  async optimizeAndUpload(file: Buffer): Promise<string> {
    // 1. WebP è½‰æ›
    const webp = await sharp(file)
      .webp({ quality: 80 })
      .toBuffer();
    
    // 2. å¤šå°ºå¯¸ç”Ÿæˆ
    const sizes = [400, 800, 1200];
    const variants = await Promise.all(
      sizes.map(width => 
        sharp(webp).resize(width).toBuffer()
      )
    );
    
    // 3. ä¸Šå‚³åˆ° S3 + CloudFront
    const urls = await this.uploadVariants(variants);
    
    return urls;
  }
}

// æ•ˆæœ: 
// åŸåœ–: 5 MB â†’ WebP: 800 KB (ç¯€çœ 84%)
// éŸ¿æ‡‰å¼è¼‰å…¥: ç”¨æˆ¶åƒ…ä¸‹è¼‰æ‰€éœ€å°ºå¯¸
```

---

## ğŸ“Š å®¹é‡è¦åŠƒç¸½è¦½

### Phase 1: ç•¶å‰ç‹€æ…‹ (50K DAU)
```
âœ… API Gateway:         1 å¯¦ä¾‹ (ä½¿ç”¨ç‡ 10%)
âœ… å¾Œç«¯æœå‹™:             13 å€‹æœå‹™ï¼Œå„ 1 å¯¦ä¾‹
âœ… PostgreSQL:          1 Master + 1 Replica (æœªå……åˆ†åˆ©ç”¨)
âœ… Redis:               1 Master + 2 Replica (ä½¿ç”¨ç‡ 30%)
âš ï¸ Kafka:               1 Broker (å–®é»æ•…éšœé¢¨éšª)
```

**å¥åº·ç‹€æ³**: ğŸŸ¢ è‰¯å¥½

---

### Phase 2: ä¸­æœŸæ“´å±• (500K DAU)

#### æ¶æ§‹å‡ç´š
```
API Gateway:        1 â†’ 2 å¯¦ä¾‹ (Nginx è² è¼‰å‡è¡¡)
æ ¸å¿ƒæœå‹™:            1 â†’ 3 å¯¦ä¾‹ (auth, user, content)
å…¶ä»–æœå‹™:            1 â†’ 2 å¯¦ä¾‹
PostgreSQL:         è®€å¯«åˆ†é›¢ï¼ˆå……åˆ†åˆ©ç”¨ Replicaï¼‰
Redis:              è¨˜æ†¶é«”æ“´å®¹ï¼ˆ768M â†’ 2GB per nodeï¼‰
Kafka:              1 Broker â†’ 3 Broker é›†ç¾¤
CDN:                æ•´åˆ CloudFront
```

#### æˆæœ¬ä¼°ç®—ï¼ˆAWSï¼‰
| çµ„ä»¶ | è¦æ ¼ | æ•¸é‡ | æœˆæˆæœ¬ (USD) |
|------|------|------|-------------|
| EC2 (t3.large) | API Gateway | 2 | $120 |
| EC2 (t3.xlarge) | å¾Œç«¯æœå‹™ | 20 | $1,200 |
| RDS (db.r5.2xlarge) | PostgreSQL | 2 | $1,200 |
| ElastiCache (cache.r5.large) | Redis | 3 | $450 |
| MSK (kafka.m5.large) | Kafka | 3 | $600 |
| ALB | è² è¼‰å‡è¡¡ | 2 | $50 |
| CloudFront | CDN | - | $200 |
| S3 + Transfer | å„²å­˜èˆ‡æµé‡ | - | $300 |
| **ç¸½è¨ˆ** | | | **$4,120/æœˆ** |

#### å¯¦æ–½æ™‚é–“è¡¨
```markdown
Month 1-2:
  âœ… Kafka é›†ç¾¤éƒ¨ç½²
  âœ… Circuit Breaker æ•´åˆ
  âœ… PostgreSQL è®€å¯«åˆ†é›¢æ‡‰ç”¨

Month 3-4:
  âœ… API Gateway è² è¼‰å‡è¡¡
  âœ… æ ¸å¿ƒæœå‹™æ°´å¹³æ“´å±•
  âœ… Redis è¨˜æ†¶é«”æ“´å®¹

Month 5-6:
  âœ… CloudFront CDN æ•´åˆ
  âœ… åœ–ç‰‡å„ªåŒ–ï¼ˆWebPï¼‰
  âœ… å£“åŠ›æ¸¬è©¦èˆ‡èª¿å„ª
```

---

### Phase 3: å¤§è¦æ¨¡æ“´å±• (5M DAU)

#### æ¶æ§‹å‡ç´š
```
API Gateway:        2 â†’ 12 å¯¦ä¾‹ï¼ˆAWS ALB Auto Scalingï¼‰
å¾Œç«¯æœå‹™:            20 â†’ 60+ å¯¦ä¾‹ï¼ˆKubernetes HPAï¼‰
PostgreSQL:         åˆ†ç‰‡ 4 å€‹ Shardï¼ˆæ¯å€‹ Master + Replicaï¼‰
Redis:              Sentinel â†’ Clusterï¼ˆ6 ç¯€é»ï¼‰
Kafka:              3 â†’ 6 Brokerï¼ˆæ›´é«˜ååé‡ï¼‰
å…¨æ–‡æœå°‹:            æ•´åˆ Elasticsearchï¼ˆ3 ç¯€é»ï¼‰
ç›£æ§:               Prometheus + Grafana + ELK
```

#### æ¶æ§‹åœ–
```
                        [Users: 5M DAU]
                              â†“
                    [CloudFront CDN]
                              â†“
                    [AWS ALB (Multi-AZ)]
                    /         |         \
             [API-GW-1] [API-GW-2] ... [API-GW-12]
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       Kubernetes Cluster (EKS)        â”‚
        â”‚   - auth-service: 10 pods             â”‚
        â”‚   - user-service: 10 pods             â”‚
        â”‚   - content-service: 15 pods          â”‚
        â”‚   - payment-service: 5 pods           â”‚
        â”‚   - ... (å…¶ä»–æœå‹™)                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Data Layer (Multi-AZ)            â”‚
        â”‚                                        â”‚
        â”‚  PostgreSQL Shards:                   â”‚
        â”‚  â”œâ”€ Shard-0 (Master + Replica)        â”‚
        â”‚  â”œâ”€ Shard-1 (Master + Replica)        â”‚
        â”‚  â”œâ”€ Shard-2 (Master + Replica)        â”‚
        â”‚  â””â”€ Shard-3 (Master + Replica)        â”‚
        â”‚                                        â”‚
        â”‚  Redis Cluster:                       â”‚
        â”‚  â”œâ”€ Node-1/2 (Master + Replica)       â”‚
        â”‚  â”œâ”€ Node-3/4 (Master + Replica)       â”‚
        â”‚  â””â”€ Node-5/6 (Master + Replica)       â”‚
        â”‚                                        â”‚
        â”‚  Kafka Cluster:                       â”‚
        â”‚  â”œâ”€ Broker-1/2/3                      â”‚
        â”‚  â””â”€ Broker-4/5/6                      â”‚
        â”‚                                        â”‚
        â”‚  Elasticsearch:                       â”‚
        â”‚  â””â”€ 3 nodes (å…¨æ–‡æœå°‹)                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æˆæœ¬ä¼°ç®—ï¼ˆAWSï¼‰
| çµ„ä»¶ | è¦æ ¼ | æ•¸é‡ | æœˆæˆæœ¬ (USD) |
|------|------|------|-------------|
| EKS Cluster | Kubernetes | 1 | $150 |
| EC2 (c5.2xlarge) | K8s Nodes | 20 | $4,000 |
| RDS (db.r5.4xlarge) | PostgreSQL | 8 | $9,600 |
| ElastiCache Cluster | Redis | 6 | $1,800 |
| MSK (kafka.m5.xlarge) | Kafka | 6 | $1,800 |
| Elasticsearch | 3 nodes | 3 | $900 |
| ALB | è² è¼‰å‡è¡¡ | 3 | $75 |
| CloudFront | CDN | - | $1,500 |
| S3 + Transfer | å„²å­˜èˆ‡æµé‡ | - | $2,000 |
| **ç¸½è¨ˆ** | | | **$21,825/æœˆ** |

**ROI åˆ†æ**:
```
å‡è¨­ ARPU (æ¯ç”¨æˆ¶æœˆå‡æ”¶å…¥) = $5
  5M DAU Ã— 30% ä»˜è²»ç‡ Ã— $5 = $7,500,000/æœˆç‡Ÿæ”¶
  åŸºç¤è¨­æ–½æˆæœ¬: $21,825/æœˆ (åƒ…ä½”ç‡Ÿæ”¶ 0.29%)
  
âœ… æˆæœ¬æ•ˆç›Šæ¥µä½³
```

#### å¯¦æ–½æ™‚é–“è¡¨
```markdown
Month 1-3:
  â³ è³‡æ–™åº«åˆ†ç‰‡è¨­è¨ˆèˆ‡å¯¦æ–½
  â³ Redis Cluster é·ç§»
  â³ Elasticsearch æ•´åˆ

Month 4-6:
  â³ Kubernetes é·ç§»ï¼ˆEKSï¼‰
  â³ Kafka æ“´å®¹ï¼ˆ6 Brokerï¼‰
  â³ å¤šå€åŸŸéƒ¨ç½²ï¼ˆus-east-1 + ap-southeast-1ï¼‰

Month 7-9:
  â³ å£“åŠ›æ¸¬è©¦ï¼ˆæ¨¡æ“¬ 5M DAUï¼‰
  â³ æ··æ²Œå·¥ç¨‹æ¸¬è©¦
  â³ æ€§èƒ½èª¿å„ªèˆ‡å„ªåŒ–

Month 10-12:
  â³ å®Œæ•´ç›£æ§é«”ç³»ï¼ˆPrometheus + Grafana + ELKï¼‰
  â³ è‡ªå‹•åŒ–å‘Šè­¦èˆ‡éŸ¿æ‡‰
  â³ ç½é›£æ¢å¾©æ¼”ç·´
```

---

## ğŸš€ æ€§èƒ½ç“¶é ¸è­˜åˆ¥

### 1. è³‡æ–™åº«æŸ¥è©¢ç“¶é ¸

#### æ…¢æŸ¥è©¢åˆ†æ
```sql
-- é–‹å•Ÿ slow query log
ALTER SYSTEM SET log_min_duration_statement = 100;  -- è¨˜éŒ„ > 100ms çš„æŸ¥è©¢

-- åˆ†æ pg_stat_statements
SELECT 
  query,
  calls,
  total_exec_time,
  mean_exec_time,
  max_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 100
ORDER BY total_exec_time DESC
LIMIT 10;
```

#### Top 5 æ…¢æŸ¥è©¢
```sql
-- 1. Feed æŸ¥è©¢ï¼ˆæœªå„ªåŒ–ï¼ŒN+1 å•é¡Œï¼‰
SELECT * FROM post 
WHERE user_id IN (SELECT followed_id FROM follow WHERE follower_id = $1)
ORDER BY created_at DESC LIMIT 20;
-- å¹³å‡åŸ·è¡Œæ™‚é–“: 850ms âŒ

-- å„ªåŒ–å¾Œ:
CREATE INDEX idx_follow_follower ON follow(follower_id, followed_id);
CREATE INDEX idx_post_user_created ON post(user_id, created_at DESC);

SELECT p.* 
FROM post p
INNER JOIN follow f ON p.user_id = f.followed_id
WHERE f.follower_id = $1
ORDER BY p.created_at DESC 
LIMIT 20;
-- å¹³å‡åŸ·è¡Œæ™‚é–“: 45ms âœ… (æå‡ 95%)
```

---

### 2. Redis å¿«å–å‘½ä¸­ç‡

```bash
redis-cli INFO stats | grep keyspace

keyspace_hits:  1,234,567
keyspace_misses: 123,456

å‘½ä¸­ç‡ = 1,234,567 / (1,234,567 + 123,456) = 90.9%
âœ… ç›®æ¨™: > 90%ï¼ˆå·²é”æ¨™ï¼‰
```

#### å¿«å–ç­–ç•¥å„ªåŒ–
```typescript
// âŒ ç•¶å‰: ç°¡å–®å¿«å–
async getUser(id: string) {
  const cached = await redis.get(`user:${id}`);
  if (cached) return JSON.parse(cached);
  
  const user = await db.findOne({ id });
  await redis.set(`user:${id}`, JSON.stringify(user));  // âš ï¸ ç„¡ TTL
  return user;
}

// âœ… å„ªåŒ–: Cache-Aside + TTL + åºåˆ—åŒ–
async getUser(id: string) {
  const cached = await redis.get(`user:${id}`);
  if (cached) {
    this.metrics.cacheHit('user');
    return msgpack.decode(cached);  // MessagePack æ›´å¿«
  }
  
  this.metrics.cacheMiss('user');
  
  const user = await db.findOne({ id });
  if (user) {
    await redis.setex(
      `user:${id}`, 
      300,  // 5 åˆ†é˜ TTL
      msgpack.encode(user)
    );
  }
  return user;
}
```

---

### 3. ç¶²è·¯å»¶é²

#### ç•¶å‰å»¶é²æ¸¬è©¦
```bash
# å…§ç¶²å»¶é² (æœå‹™é–“)
ping api-gateway â†’ auth-service: ~0.5ms âœ…
ping auth-service â†’ postgres: ~1.2ms âœ…

# å¤–ç¶²å»¶é² (ç”¨æˆ¶åˆ° API)
US East Coast â†’ API: 20ms âœ…
Europe â†’ API: 120ms ğŸŸ¡
Asia â†’ API: 250ms âŒ (éœ€ CDN + å¤šå€åŸŸéƒ¨ç½²)
```

#### å„ªåŒ–ç­–ç•¥
```markdown
1. CloudFront CDN (éœæ…‹è³‡æº)
   - é‚Šç·£ç¯€é»å¿«å–
   - æ¸›å°‘ 80% çš„ S3 è«‹æ±‚
   
2. Multi-Region Deployment
   - us-east-1 (ç¾åœ‹)
   - eu-west-1 (æ­æ´²)
   - ap-southeast-1 (äºæ´²)
   
3. Database Read Replicas (è·¨å€åŸŸ)
   - è®€å–è«‹æ±‚å°±è¿‘è™•ç†
   - å¯«å…¥ä»ç„¶é›†ä¸­åˆ°ä¸»å€åŸŸï¼ˆæ¥å—å»¶é²ï¼‰
```

---

## ğŸ“ˆ å®¹é‡è¦åŠƒæœ€ä½³å¯¦è¸

### 1. æŒçºŒç›£æ§
```yaml
# Prometheus æŒ‡æ¨™æ”¶é›†
- API Gateway QPS
- å¾Œç«¯æœå‹™ CPU/Memory ä½¿ç”¨ç‡
- è³‡æ–™åº«é€£æ¥æ•¸ã€QPSã€æ…¢æŸ¥è©¢
- Redis è¨˜æ†¶é«”ä½¿ç”¨ç‡ã€å‘½ä¸­ç‡
- Kafka è¨Šæ¯å †ç©ï¼ˆLagï¼‰
- ç¶²è·¯æµé‡
```

### 2. è‡ªå‹•æ“´å±•è¦å‰‡
```yaml
# Kubernetes HPA é…ç½®
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: auth-service
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: auth-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

### 3. å®¹é‡é è­¦
```yaml
# Prometheus Alert Rules
groups:
- name: capacity
  rules:
  - alert: HighCPUUsage
    expr: avg(rate(container_cpu_usage_seconds_total[5m])) > 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "CPU ä½¿ç”¨ç‡è¶…é 80%"
      
  - alert: DatabaseConnectionPoolNearLimit
    expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "è³‡æ–™åº«é€£æ¥æ± ä½¿ç”¨ç‡ > 80%"
      
  - alert: RedisMemoryNearLimit
    expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Redis è¨˜æ†¶é«”ä½¿ç”¨ç‡ > 90%"
```

---

## ğŸ¯ ç¸½çµèˆ‡å»ºè­°

### ç•¶å‰ç‹€æ…‹ (50K DAU)
- âœ… **ç„¡éœ€ç«‹å³æ“´å±•**ï¼šæ‰€æœ‰çµ„ä»¶ä½¿ç”¨ç‡ < 30%
- âš ï¸ **Kafka å–®é»é¢¨éšª**ï¼šå»ºè­°ç›¡å¿«å‡ç´šç‚ºé›†ç¾¤
- ğŸŸ¢ **å¥åº·ç‹€æ…‹**ï¼šå¯æ”¯æ´è‡³å°‘ 3 å€‹æœˆ

### æ“´å±•è·¯ç·šåœ–
```
Phase 1 (ç•¶å‰):    50K DAU    âœ… å¥åº·
Phase 2 (6å€‹æœˆ):   500K DAU   ğŸŸ¡ éœ€å‡ç´š
Phase 3 (12å€‹æœˆ):  5M DAU     ğŸ”´ éœ€å¤§å¹…æ¶æ§‹èª¿æ•´
```

### é—œéµè¡Œå‹•é …ç›®
```markdown
P0 (ç«‹å³):
  [ ] Kafka é›†ç¾¤éƒ¨ç½²ï¼ˆ3 ç¯€é»ï¼‰
  [ ] PostgreSQL é€£æ¥æ± å„ªåŒ–
  [ ] è³‡æ–™åº«å‚™ä»½è‡ªå‹•åŒ–

P1 (3å€‹æœˆ):
  [ ] API Gateway è² è¼‰å‡è¡¡
  [ ] PostgreSQL è®€å¯«åˆ†é›¢æ‡‰ç”¨
  [ ] Redis è¨˜æ†¶é«”æ“´å®¹
  [ ] CloudFront CDN æ•´åˆ

P2 (6-12å€‹æœˆ):
  [ ] è³‡æ–™åº«åˆ†ç‰‡è¨­è¨ˆ
  [ ] Kubernetes é·ç§»
  [ ] å¤šå€åŸŸéƒ¨ç½²
  [ ] Elasticsearch å…¨æ–‡æœå°‹
```

---

**è² è²¬äºº**: æ¶æ§‹åœ˜éšŠ + DevOps åœ˜éšŠ
**ä¸‹æ¬¡è©•ä¼°**: 2024 å¹´ 5 æœˆ
**æ–‡æª”ç‰ˆæœ¬**: v1.0 (2024-02)
