# Canary Deployment - Monitoring & Alerting Rules
# Prometheus Configuration for FINAL-002
# Date: 2026-02-19

groups:
  - name: canary_deployment_alerts
    interval: 30s
    rules:
      # Phase 1: Critical Alerts (5% Canary)
      - alert: CanaryHighErrorRate
        expr: |
          (sum(rate(http_requests_total{status=~"5.."}[5m])) / 
           sum(rate(http_requests_total[5m]))) > 0.05
        for: 2m
        labels:
          severity: critical
          phase: canary
        annotations:
          summary: "High error rate detected in canary deployment"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
          action: "Trigger automatic rollback for Phase 1"

      - alert: CanaryHighLatency
        expr: histogram_quantile(0.99, http_request_duration_seconds) > 2
        for: 3m
        labels:
          severity: critical
          phase: canary
        annotations:
          summary: "High latency detected in canary"
          description: "P99 latency is {{ $value | humanizeDuration }} (threshold: 2s)"

      - alert: CanaryPodCrashLoop
        expr: |
          rate(kube_pod_container_status_restarts_total{
            pod=~"canary-.*"
          }[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
          phase: canary
        annotations:
          summary: "Pod crash loop detected in canary"
          description: "Pod {{ $labels.pod }} is restarting frequently"

      # Phase 2: Expansion Alerts (25% Traffic)
      - alert: ExpansionHighErrorRate
        expr: |
          (sum(rate(http_requests_total{status=~"5.."}[5m])) / 
           sum(rate(http_requests_total[5m]))) > 0.10
        for: 2m
        labels:
          severity: warning
          phase: expansion
        annotations:
          summary: "High error rate in Phase 2 (25%)"
          description: "Error rate is {{ $value | humanizePercentage }}"

      - alert: DatabaseConnectionPoolAlmostFull
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections > 0.85
        for: 2m
        labels:
          severity: warning
          phase: expansion
        annotations:
          summary: "Database connection pool near capacity"
          description: "{{ $value | humanizePercentage }} of connections used"

      # Phase 3: Performance Validation (50% Traffic)
      - alert: MajorityReleaseHighMemory
        expr: process_resident_memory_bytes > 1073741824  # 1GB
        for: 3m
        labels:
          severity: warning
          phase: majority
        annotations:
          summary: "High memory usage in Phase 3"
          description: "Memory usage is {{ $value | humanize }}B"

      - alert: MajorityReleaseCPUSpike
        expr: rate(process_cpu_seconds_total[5m]) > 0.8
        for: 2m
        labels:
          severity: warning
          phase: majority
        annotations:
          summary: "CPU spike detected in Phase 3"
          description: "CPU usage is {{ $value | humanizePercentage }}"

      # General Deployment Alerts
      - alert: DeploymentReplicasMismatch
        expr: |
          kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Deployment replicas mismatch"
          description: "Expected {{ $value }} replicas but only {{ $value }} available"

      - alert: DatabaseQueryLatencyHigh
        expr: histogram_quantile(0.95, mysql_query_response_time) > 1
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "Database query latency is high"
          description: "P95 query latency is {{ $value | humanizeDuration }}"

      - alert: CacheHitRatioLow
        expr: redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) < 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Cache hit ratio is below 80%"
          description: "Current hit ratio: {{ $value | humanizePercentage }}"

---

# Service Level Indicator (SLI) Rules
groups:
  - name: canary_sli_metrics
    interval: 30s
    rules:
      - record: sli:http:success_rate
        expr: |
          (sum(rate(http_requests_total{status!~"5.."}[5m])) / 
           sum(rate(http_requests_total[5m]))) * 100

      - record: sli:http:latency_p99
        expr: histogram_quantile(0.99, http_request_duration_seconds)

      - record: sli:http:latency_p95
        expr: histogram_quantile(0.95, http_request_duration_seconds)

      - record: sli:http:latency_p50
        expr: histogram_quantile(0.50, http_request_duration_seconds)

      - record: sli:database:connection_usage
        expr: |
          mysql_global_status_threads_connected / 
          mysql_global_variables_max_connections * 100

      - record: sli:cache:hit_ratio
        expr: |
          redis_keyspace_hits_total / 
          (redis_keyspace_hits_total + redis_keyspace_misses_total) * 100

---

# Recording Rules for Dashboard
groups:
  - name: canary_dashboard_metrics
    interval: 1m
    rules:
      # Request rate by status code
      - record: canary:request_rate:by_status
        expr: sum(rate(http_requests_total[5m])) by (status)

      # Error rate (5xx)
      - record: canary:error_rate
        expr: sum(rate(http_requests_total{status=~"5.."}[5m]))

      # Request latency percentiles
      - record: canary:latency_p50
        expr: histogram_quantile(0.50, http_request_duration_seconds)

      - record: canary:latency_p95
        expr: histogram_quantile(0.95, http_request_duration_seconds)

      - record: canary:latency_p99
        expr: histogram_quantile(0.99, http_request_duration_seconds)

      # Resource utilization
      - record: canary:memory_usage
        expr: process_resident_memory_bytes / 1073741824  # In GB

      - record: canary:cpu_usage
        expr: rate(process_cpu_seconds_total[5m]) * 100

      # Pod count by status
      - record: canary:pods_ready
        expr: count(kube_pod_status_phase{phase="Running"})

      - record: canary:pods_crashed
        expr: count(kube_pod_status_phase{phase="CrashLoopBackOff"})

---

# Notification Rules
groups:
  - name: canary_notifications
    interval: 30s
    rules:
      - alert: DeploymentStarted
        expr: ALERTS{job="canary"} == 1
        for: 0s
        labels:
          severity: info
          channel: "deployment-alerts"
        annotations:
          summary: "Canary deployment started"
          description: "Beginning deployment of new version"

      - alert: PhaseCompleted
        expr: deployment_phase_completed == 1
        for: 0s
        labels:
          severity: info
          channel: "deployment-alerts"
        annotations:
          summary: "Deployment phase completed"
          description: "Phase {{ $labels.phase }} completed successfully"

---

# Dashboard Definition (Grafana JSON)
groups:
  - name: canary_grafana_dashboard
    interval: 30s
    rules:
      # Golden Signal Metrics
      - record: golden:errors
        expr: sum(rate(http_requests_total{status=~"5.."}[5m])) by (instance)

      - record: golden:latency
        expr: histogram_quantile(0.99, http_request_duration_seconds) by (instance)

      - record: golden:traffic
        expr: sum(rate(http_requests_total[5m])) by (instance)

      - record: golden:saturation
        expr: (process_resident_memory_bytes / 1073741824) / 8  # Assuming 8GB limit
