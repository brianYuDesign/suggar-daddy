version: '3.8'

services:
  # Database Services - High Availability Architecture
  # =====================================================
  # PostgreSQL Master-Replica Setup with Streaming Replication
  
  # PostgreSQL Master (Primary)
  postgres-master:
    image: postgres:16-alpine
    container_name: suggar-daddy-postgres-master
    hostname: postgres-master
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      REPLICATION_PASSWORD: ${REPLICATION_PASSWORD:-replicator_password}
      # Performance tuning
      POSTGRES_SHARED_BUFFERS: ${POSTGRES_SHARED_BUFFERS:-256MB}
      POSTGRES_EFFECTIVE_CACHE_SIZE: ${POSTGRES_EFFECTIVE_CACHE_SIZE:-1GB}
      POSTGRES_WORK_MEM: ${POSTGRES_WORK_MEM:-8MB}
      POSTGRES_MAINTENANCE_WORK_MEM: ${POSTGRES_MAINTENANCE_WORK_MEM:-128MB}
      POSTGRES_MAX_CONNECTIONS: ${POSTGRES_MAX_CONNECTIONS:-200}
    ports:
      - "5432:5432"
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/master/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./infrastructure/postgres/master/pg_hba.conf:/etc/postgresql/pg_hba.conf
      - ./infrastructure/postgres/scripts/init-master.sh:/docker-entrypoint-initdb.d/01-init-master.sh
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/02-init-db.sql
      - ./infrastructure/postgres/scripts/check-replication.sh:/usr/local/bin/check-replication.sh
      - ./backups:/backups
      - postgres_wal_archive:/var/lib/postgresql/wal_archive
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres && psql -U postgres -c 'SELECT 1' > /dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1024M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    labels:
      - "postgres.role=master"
      - "postgres.cluster=suggar-daddy"

  # PostgreSQL Replica (Standby) - Read-Only
  postgres-replica:
    image: postgres:16-alpine
    container_name: suggar-daddy-postgres-replica
    hostname: postgres-replica
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      POSTGRES_MASTER_HOST: postgres-master
      POSTGRES_MASTER_PORT: 5432
      REPLICATION_PASSWORD: ${REPLICATION_PASSWORD:-replicator_password}
      PGDATA: /var/lib/postgresql/data
    ports:
      - "5433:5432"
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/replica/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./infrastructure/postgres/replica/pg_hba.conf:/etc/postgresql/pg_hba.conf
      - ./infrastructure/postgres/replica/entrypoint.sh:/usr/local/bin/replica-entrypoint.sh
      - ./infrastructure/postgres/scripts/check-replication.sh:/usr/local/bin/check-replication.sh
      - ./backups:/backups
      - postgres_wal_archive:/var/lib/postgresql/wal_archive
    entrypoint: ["/usr/local/bin/replica-entrypoint.sh"]
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    depends_on:
      postgres-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres && psql -U postgres -c 'SELECT pg_is_in_recovery()' | grep -q 't'"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1024M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    labels:
      - "postgres.role=replica"
      - "postgres.cluster=suggar-daddy"

  # Legacy alias for backward compatibility
  # Services can still connect to 'postgres'
  postgres:
    image: alpine:latest
    container_name: suggar-daddy-postgres-proxy
    command: /bin/sh -c "echo 'Legacy postgres service - use postgres-master or postgres-replica' && tail -f /dev/null"
    depends_on:
      - postgres-master
    networks:
      - suggar-daddy-network
    profiles:
      - legacy

  # Redis Sentinel Architecture for High Availability
  # =====================================================
  
  # Redis Master - 主節點，處理寫入操作
  redis-master:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-master
    ports:
      - "6379:6379"
    volumes:
      - redis_master_data:/data
      - ./infrastructure/redis/master/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./backups:/backups
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Replica 1 - 從節點 1，處理讀取操作
  redis-replica-1:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-replica-1
    ports:
      - "6380:6379"
    volumes:
      - redis_replica_1_data:/data
      - ./infrastructure/redis/replica/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./backups:/backups
    command: >
      sh -c "redis-server /usr/local/etc/redis/redis.conf
      --replicaof redis-master 6379"
    depends_on:
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Replica 2 - 從節點 2，處理讀取操作
  redis-replica-2:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-replica-2
    ports:
      - "6381:6379"
    volumes:
      - redis_replica_2_data:/data
      - ./infrastructure/redis/replica/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./backups:/backups
    command: >
      sh -c "redis-server /usr/local/etc/redis/redis.conf
      --replicaof redis-master 6379"
    depends_on:
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Sentinel 1 - 哨兵節點 1
  redis-sentinel-1:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-sentinel-1
    ports:
      - "26379:26379"
    volumes:
      - redis_sentinel_1_data:/data
      - ./infrastructure/redis/sentinel/sentinel.conf:/usr/local/etc/redis/sentinel.conf:rw
    command: redis-sentinel /usr/local/etc/redis/sentinel.conf
    depends_on:
      redis-master:
        condition: service_healthy
      redis-replica-1:
        condition: service_healthy
      redis-replica-2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "26379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Sentinel 2 - 哨兵節點 2
  redis-sentinel-2:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-sentinel-2
    ports:
      - "26380:26379"
    volumes:
      - redis_sentinel_2_data:/data
      - ./infrastructure/redis/sentinel/sentinel.conf:/usr/local/etc/redis/sentinel.conf:rw
    command: redis-sentinel /usr/local/etc/redis/sentinel.conf
    depends_on:
      redis-master:
        condition: service_healthy
      redis-replica-1:
        condition: service_healthy
      redis-replica-2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "26379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Sentinel 3 - 哨兵節點 3
  redis-sentinel-3:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-sentinel-3
    ports:
      - "26381:26379"
    volumes:
      - redis_sentinel_3_data:/data
      - ./infrastructure/redis/sentinel/sentinel.conf:/usr/local/etc/redis/sentinel.conf:rw
    command: redis-sentinel /usr/local/etc/redis/sentinel.conf
    depends_on:
      redis-master:
        condition: service_healthy
      redis-replica-1:
        condition: service_healthy
      redis-replica-2:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "26379", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Kafka & Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: suggar-daddy-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: suggar-daddy-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      # Performance tuning
      KAFKA_NUM_NETWORK_THREADS: 3
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
      KAFKA_COMPRESSION_TYPE: lz4
      KAFKA_MESSAGE_MAX_BYTES: 1048576
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1024M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network

  # Backend Services
  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: api-gateway
    container_name: suggar-daddy-api-gateway
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3000
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:4200,http://localhost:4300}
      # Service URLs
      AUTH_SERVICE_URL: http://auth-service:3002
      USER_SERVICE_URL: http://user-service:3001
      PAYMENT_SERVICE_URL: http://payment-service:3007
      SUBSCRIPTION_SERVICE_URL: http://subscription-service:3009
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:api-gateway
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  auth-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: auth-service
    container_name: suggar-daddy-auth-service
    ports:
      - "3002:3002"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3002
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      # Redis (連接到 Sentinel)
      REDIS_SENTINELS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_MASTER_NAME: mymaster
      # Kafka
      KAFKA_BROKERS: kafka:9092
      KAFKA_CLIENT_ID: auth-service
      KAFKA_GROUP_ID: auth-service-group
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-7d}
      # Email / SMTP (optional, with defaults for dev)
      SMTP_HOST: ${SMTP_HOST:-localhost}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USER: ${SMTP_USER:-}
      SMTP_PASSWORD: ${SMTP_PASSWORD:-}
      EMAIL_FROM: ${EMAIL_FROM:-noreply@suggar-daddy.com}
      APP_BASE_URL: ${APP_BASE_URL:-http://localhost:4200}
      # Firebase (optional)
      FIREBASE_PROJECT_ID: ${FIREBASE_PROJECT_ID:-}
      FIREBASE_CLIENT_EMAIL: ${FIREBASE_CLIENT_EMAIL:-}
      FIREBASE_PRIVATE_KEY: ${FIREBASE_PRIVATE_KEY:-}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:auth-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  user-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: user-service
    container_name: suggar-daddy-user-service
    ports:
      - "3001:3001"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3001
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      # Redis (連接到 Sentinel)
      REDIS_SENTINELS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_MASTER_NAME: mymaster
      # Cloudinary (for file uploads)
      CLOUDINARY_CLOUD_NAME: ${CLOUDINARY_CLOUD_NAME:-}
      CLOUDINARY_API_KEY: ${CLOUDINARY_API_KEY:-}
      CLOUDINARY_API_SECRET: ${CLOUDINARY_API_SECRET:-}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:user-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  payment-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: payment-service
    container_name: suggar-daddy-payment-service
    ports:
      - "3007:3007"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3007
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      # Redis (連接到 Sentinel)
      REDIS_SENTINELS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_MASTER_NAME: mymaster
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # Stripe
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-}
      STRIPE_PUBLISHABLE_KEY: ${STRIPE_PUBLISHABLE_KEY:-}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:payment-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  subscription-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: subscription-service
    container_name: suggar-daddy-subscription-service
    ports:
      - "3009:3009"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3009
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      # Redis (連接到 Sentinel)
      REDIS_SENTINELS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_MASTER_NAME: mymaster
      # Kafka
      KAFKA_BROKERS: kafka:9092
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:subscription-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  db-writer-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: db-writer-service
    container_name: suggar-daddy-db-writer-service
    ports:
      - "3010:3010"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3010
      # Database
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      # Redis (連接到 Sentinel)
      REDIS_SENTINELS: redis-sentinel-1:26379,redis-sentinel-2:26379,redis-sentinel-3:26379
      REDIS_MASTER_NAME: mymaster
      # Kafka
      KAFKA_BROKERS: kafka:9092
      KAFKA_GROUP_ID: db-writer-group
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:db-writer-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Optional: Additional services from package.json
  matching-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: matching-service
    container_name: suggar-daddy-matching-service
    ports:
      - "3003:3003"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3003
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:matching-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  notification-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: notification-service
    container_name: suggar-daddy-notification-service
    ports:
      - "3004:3004"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3004
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      KAFKA_BROKERS: kafka:9092
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:notification-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  messaging-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: messaging-service
    container_name: suggar-daddy-messaging-service
    ports:
      - "3005:3005"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3005
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:messaging-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  admin-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: admin-service
    container_name: suggar-daddy-admin-service
    ports:
      - "3006:3006"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3006
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:admin-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  # Frontend Applications
  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
      target: development
    container_name: suggar-daddy-web
    ports:
      - "4200:4200"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3000}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - api-gateway
    command: npm run serve:web
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - frontend

  admin:
    build:
      context: .
      dockerfile: apps/admin/Dockerfile
      target: development
    container_name: suggar-daddy-admin
    ports:
      - "4300:4300"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3000}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - api-gateway
    command: npm run serve:admin
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - frontend

networks:
  suggar-daddy-network:
    driver: bridge

volumes:
  # PostgreSQL High Availability Volumes
  postgres_master_data:
    driver: local
  postgres_replica_data:
    driver: local
  postgres_wal_archive:
    driver: local
  # Legacy volume (kept for backward compatibility)
  postgres_data:
    driver: local
  
  # Redis High Availability Volumes
  redis_master_data:
    driver: local
  redis_replica_1_data:
    driver: local
  redis_replica_2_data:
    driver: local
  redis_sentinel_1_data:
    driver: local
  redis_sentinel_2_data:
    driver: local
  redis_sentinel_3_data:
    driver: local
  # Legacy volume (kept for backward compatibility)
  redis_data:
    driver: local
  
  # Kafka & Zookeeper Volumes
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
