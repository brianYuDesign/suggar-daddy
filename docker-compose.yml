version: "3.8"

services:
  # Database Services - High Availability Architecture
  # =====================================================
  # PostgreSQL Master-Replica Setup with Streaming Replication

  # PostgreSQL Master (Primary)
  postgres-master:
    image: postgres:16-alpine
    container_name: suggar-daddy-postgres-master
    hostname: postgres-master
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      REPLICATION_PASSWORD: ${REPLICATION_PASSWORD:-replicator_password}
      # Performance tuning
      POSTGRES_SHARED_BUFFERS: ${POSTGRES_SHARED_BUFFERS:-256MB}
      POSTGRES_EFFECTIVE_CACHE_SIZE: ${POSTGRES_EFFECTIVE_CACHE_SIZE:-1GB}
      POSTGRES_WORK_MEM: ${POSTGRES_WORK_MEM:-8MB}
      POSTGRES_MAINTENANCE_WORK_MEM: ${POSTGRES_MAINTENANCE_WORK_MEM:-128MB}
      POSTGRES_MAX_CONNECTIONS: ${POSTGRES_MAX_CONNECTIONS:-200}
    ports:
      - "5432:5432"
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/master/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./infrastructure/postgres/master/pg_hba.conf:/etc/postgresql/pg_hba.conf
      - ./infrastructure/postgres/scripts/init-master.sh:/docker-entrypoint-initdb.d/01-init-master.sh
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/02-init-db.sql
      - ./infrastructure/postgres/scripts/check-replication.sh:/usr/local/bin/check-replication.sh
      - ./backups:/backups
      - postgres_wal_archive:/var/lib/postgresql/wal_archive
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U postgres && psql -U postgres -c 'SELECT 1' > /dev/null 2>&1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1024M
        reservations:
          cpus: "0.5"
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    labels:
      - "postgres.role=master"
      - "postgres.cluster=suggar-daddy"

  # PostgreSQL Replica (Standby) - Read-Only
  postgres-replica:
    image: postgres:16-alpine
    container_name: suggar-daddy-postgres-replica
    hostname: postgres-replica
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-suggar_daddy}
      POSTGRES_MASTER_HOST: postgres-master
      POSTGRES_MASTER_PORT: 5432
      REPLICATION_PASSWORD: ${REPLICATION_PASSWORD:-replicator_password}
      PGDATA: /var/lib/postgresql/data
    ports:
      - "5433:5432"
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/replica/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./infrastructure/postgres/replica/pg_hba.conf:/etc/postgresql/pg_hba.conf
      - ./infrastructure/postgres/replica/entrypoint.sh:/usr/local/bin/replica-entrypoint.sh
      - ./infrastructure/postgres/scripts/check-replication.sh:/usr/local/bin/check-replication.sh
      - ./backups:/backups
      - postgres_wal_archive:/var/lib/postgresql/wal_archive
    entrypoint: ["/usr/local/bin/replica-entrypoint.sh"]
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    depends_on:
      postgres-master:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U postgres && psql -U postgres -c 'SELECT pg_is_in_recovery()' | grep -q 't'",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1024M
        reservations:
          cpus: "0.5"
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    labels:
      - "postgres.role=replica"
      - "postgres.cluster=suggar-daddy"

  # Redis Sentinel Architecture for High Availability
  # =====================================================

  # Redis Master - 主節點，處理寫入操作
  redis-master:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-master
    ports:
      - "6379:6379"
    volumes:
      - redis_master_data:/data
      - ./infrastructure/redis/master/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./backups:/backups
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 768M
        reservations:
          cpus: "0.25"
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Replica 1 - 從節點 1，處理讀取操作
  redis-replica-1:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-replica-1
    ports:
      - "6380:6379"
    volumes:
      - redis_replica_1_data:/data
      - ./infrastructure/redis/replica/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./backups:/backups
    command: >
      sh -c "redis-server /usr/local/etc/redis/redis.conf
      --replicaof redis-master 6379"
    depends_on:
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 768M
        reservations:
          cpus: "0.25"
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Redis Replica 2 - 從節點 2，處理讀取操作
  redis-replica-2:
    image: redis:7-alpine
    container_name: suggar-daddy-redis-replica-2
    ports:
      - "6381:6379"
    volumes:
      - redis_replica_2_data:/data
      - ./infrastructure/redis/replica/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - ./backups:/backups
    command: >
      sh -c "redis-server /usr/local/etc/redis/redis.conf
      --replicaof redis-master 6379"
    depends_on:
      redis-master:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 768M
        reservations:
          cpus: "0.25"
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Kafka & Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: suggar-daddy-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: suggar-daddy-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Performance tuning
      KAFKA_NUM_NETWORK_THREADS: 3
      KAFKA_NUM_IO_THREADS: 8
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
      KAFKA_COMPRESSION_TYPE: lz4
      KAFKA_MESSAGE_MAX_BYTES: 1048576
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test:
        [
          "CMD",
          "kafka-broker-api-versions",
          "--bootstrap-server",
          "localhost:9092",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1024M
        reservations:
          cpus: "0.5"
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network

  # Backend Services
  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: api-gateway
    container_name: suggar-daddy-api-gateway
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3000
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:4200,http://localhost:4300}
      # Service URLs
      AUTH_SERVICE_URL: http://auth-service:3002
      USER_SERVICE_URL: http://user-service:3001
      MATCHING_SERVICE_URL: http://matching-service:3003
      NOTIFICATION_SERVICE_URL: http://notification-service:3004
      MESSAGING_SERVICE_URL: http://messaging-service:3005
      CONTENT_SERVICE_URL: http://content-service:3006
      PAYMENT_SERVICE_URL: http://payment-service:3007
      SUBSCRIPTION_SERVICE_URL: http://subscription-service:3009
      SKILL_SERVICE_URL: http://skill-service:3010
      MEDIA_SERVICE_URL: http://media-service:3008
      ADMIN_SERVICE_URL: http://admin-service:3011
      # Redis
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
      NODE_ENV_OTEL: ${NODE_ENV_OTEL:-development}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:api-gateway
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3000/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  auth-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: auth-service
    container_name: suggar-daddy-auth-service
    ports:
      - "3002:3002"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3002
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      # Redis
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      KAFKA_CLIENT_ID: auth-service
      KAFKA_GROUP_ID: auth-service-group
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-7d}
      # Email / SMTP (optional, with defaults for dev)
      SMTP_HOST: ${SMTP_HOST:-localhost}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USER: ${SMTP_USER:-}
      SMTP_PASSWORD: ${SMTP_PASSWORD:-}
      EMAIL_FROM: ${EMAIL_FROM:-noreply@suggar-daddy.com}
      APP_BASE_URL: ${APP_BASE_URL:-http://localhost:4200}
      # Firebase (optional)
      FIREBASE_PROJECT_ID: ${FIREBASE_PROJECT_ID:-}
      FIREBASE_CLIENT_EMAIL: ${FIREBASE_CLIENT_EMAIL:-}
      FIREBASE_PRIVATE_KEY: ${FIREBASE_PRIVATE_KEY:-}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:auth-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  user-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: user-service
    container_name: suggar-daddy-user-service
    ports:
      - "3001:3001"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3001
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      # Redis
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # Cloudinary (for file uploads)
      CLOUDINARY_CLOUD_NAME: ${CLOUDINARY_CLOUD_NAME:-}
      CLOUDINARY_API_KEY: ${CLOUDINARY_API_KEY:-}
      CLOUDINARY_API_SECRET: ${CLOUDINARY_API_SECRET:-}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:user-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  payment-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: payment-service
    container_name: suggar-daddy-payment-service
    ports:
      - "3007:3007"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3007
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      # Redis
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # Stripe
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-}
      STRIPE_PUBLISHABLE_KEY: ${STRIPE_PUBLISHABLE_KEY:-}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:payment-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  subscription-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: subscription-service
    container_name: suggar-daddy-subscription-service
    ports:
      - "3009:3009"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3009
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      # Redis
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:subscription-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  db-writer-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: db-writer-service
    container_name: suggar-daddy-db-writer-service
    ports:
      - "3010:3010"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3010
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      # Redis
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      KAFKA_GROUP_ID: db-writer-group
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:db-writer-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Optional: Additional services from package.json
  matching-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: matching-service
    container_name: suggar-daddy-matching-service
    ports:
      - "3003:3003"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3003
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:matching-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  notification-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: notification-service
    container_name: suggar-daddy-notification-service
    ports:
      - "3004:3004"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3004
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      KAFKA_BROKERS: kafka:9092
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:notification-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  messaging-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: messaging-service
    container_name: suggar-daddy-messaging-service
    ports:
      - "3005:3005"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3005
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:messaging-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  admin-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: admin-service
    container_name: suggar-daddy-admin-service
    ports:
      - "3011:3011"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3011
      ADMIN_SERVICE_PORT: 3011
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      # Kafka
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
    command: npm run serve:admin-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - full

  # Content Service
  content-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: content-service
    container_name: suggar-daddy-content-service
    ports:
      - "3006:3006"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3006
      CONTENT_SERVICE_PORT: 3006
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:content-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Media Service
  media-service:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
      args:
        APP_NAME: media-service
    container_name: suggar-daddy-media-service
    ports:
      - "3008:3008"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3008
      MEDIA_SERVICE_PORT: 3008
      # Database
      DB_HOST: postgres-master
      DB_PORT: 5432
      DB_USERNAME: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_DATABASE: ${POSTGRES_DB:-suggar_daddy}
      REDIS_HOST: redis-master
      REDIS_PORT: 6379
      KAFKA_BROKERS: kafka:9092
      # JWT
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-jwt-key-change-in-production}
      # Cloudinary (for media uploads)
      CLOUDINARY_CLOUD_NAME: ${CLOUDINARY_CLOUD_NAME:-}
      CLOUDINARY_API_KEY: ${CLOUDINARY_API_KEY:-}
      CLOUDINARY_API_SECRET: ${CLOUDINARY_API_SECRET:-}
      # OpenTelemetry / Jaeger
      JAEGER_ENDPOINT: ${JAEGER_ENDPOINT:-http://jaeger:4318/v1/traces}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/dist
    depends_on:
      postgres-master:
        condition: service_healthy
      redis-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
    command: npm run serve:media-service
    networks:
      - suggar-daddy-network
    restart: unless-stopped

  # Frontend Applications
  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
      target: development
    container_name: suggar-daddy-web
    ports:
      - "4200:4200"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3000}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - api-gateway
    command: npm run serve:web
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - frontend

  admin:
    build:
      context: .
      dockerfile: apps/admin/Dockerfile
      target: development
    container_name: suggar-daddy-admin
    ports:
      - "4300:4300"
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3000}
    volumes:
      - .:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - api-gateway
    command: npm run serve:admin
    networks:
      - suggar-daddy-network
    restart: unless-stopped
    profiles:
      - frontend

  # Jaeger - Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: suggar-daddy-jaeger
    hostname: jaeger
    ports:
      # Jaeger UI
      - "16686:16686"
      # OTLP gRPC Receiver
      - "4317:4317"
      # OTLP HTTP Receiver
      - "4318:4318"
      # Jaeger Collector HTTP
      - "14268:14268"
      # Jaeger Agent (Thrift)
      - "6831:6831/udp"
      # Admin port
      - "14269:14269"
    environment:
      # Log level: debug, info, warn, error
      COLLECTOR_OTLP_ENABLED: "true"
      COLLECTOR_GRPC_HOST_PORT: "0.0.0.0:4317"
      COLLECTOR_HTTP_HOST_PORT: "0.0.0.0:4318"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:14269/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - suggar-daddy-network
    restart: unless-stopped


  # ============ MONITORING STACK (from remote) ============
  
  prometheus:
    image: prom/prometheus:latest
    container_name: sugar-daddy-prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - sugar-daddy-network
    profiles:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    container_name: sugar-daddy-alertmanager
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    networks:
      - sugar-daddy-network
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: sugar-daddy-grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: \${GRAFANA_PASSWORD:-admin}
      GF_SECURITY_ADMIN_USER: \${GRAFANA_USER:-admin}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-clock-panel
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3001:3000"
    networks:
      - sugar-daddy-network
    profiles:
      - monitoring

  node-exporter:
    image: prom/node-exporter:latest
    container_name: sugar-daddy-node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)(\$\$|/)'
    ports:
      - "9100:9100"
    networks:
      - sugar-daddy-network
    profiles:
      - monitoring

  # ============ ELK STACK (from remote) ============
  
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: sugar-daddy-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - sugar-daddy-network
    profiles:
      - elk

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    container_name: sugar-daddy-logstash
    environment:
      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
    volumes:
      - ./monitoring/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    networks:
      - sugar-daddy-network
    depends_on:
      - elasticsearch
    profiles:
      - elk

  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.0
    container_name: sugar-daddy-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - xpack.security.enabled=false
    ports:
      - "5601:5601"
    networks:
      - sugar-daddy-network
    depends_on:
      - elasticsearch
    profiles:
      - elk

networks:
  suggar-daddy-network:
    driver: bridge

volumes:
  # PostgreSQL High Availability Volumes
  postgres_master_data:
    driver: local
  postgres_replica_data:
    driver: local
  postgres_wal_archive:
    driver: local

  # Redis High Availability Volumes
  redis_master_data:
    driver: local
  redis_replica_1_data:
    driver: local
  redis_replica_2_data:
    driver: local

  # Kafka & Zookeeper Volumes
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local

# ============================================================
# Docker Secrets Configuration
# ============================================================
# Secrets 提供安全的方式來管理敏感資料
# 使用方式：
#   1. 執行 ./scripts/setup-secrets.sh 生成 secrets
#   2. Secrets 會掛載到容器的 /run/secrets/ 目錄
#   3. 應用程式可以從檔案讀取 secrets
# ============================================================

secrets:
  # 資料庫 Secrets
  db_password:
    file: ./secrets/db_password.txt
  replication_password:
    file: ./secrets/replication_password.txt
  
  # Redis Secrets (可選)
  redis_password:
    file: ./secrets/redis_password.txt
  
  # JWT Secrets
  jwt_secret:
    file: ./secrets/jwt_secret.txt
  
  # Stripe Secrets
  stripe_secret_key:
    file: ./secrets/stripe_secret_key.txt
  stripe_webhook_secret:
    file: ./secrets/stripe_webhook_secret.txt
  stripe_publishable_key:
    file: ./secrets/stripe_publishable_key.txt
  
  # Cloudinary Secrets
  cloudinary_cloud_name:
    file: ./secrets/cloudinary_cloud_name.txt
  cloudinary_api_key:
    file: ./secrets/cloudinary_api_key.txt
  cloudinary_api_secret:
    file: ./secrets/cloudinary_api_secret.txt
  
  # Firebase Secrets (可選)
  firebase_private_key:
    file: ./secrets/firebase_private_key.txt
  
  # SMTP Secrets (可選)
  smtp_password:
    file: ./secrets/smtp_password.txt

  # Monitoring & ELK Volumes
  prometheus_data:
    driver: local
  alertmanager_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local
